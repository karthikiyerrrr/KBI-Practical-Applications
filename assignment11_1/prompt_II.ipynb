{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What drives the price of a car?\n",
    "\n",
    "![](images/kurt.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERVIEW**\n",
    "\n",
    "In this application, you will explore a dataset from Kaggle. The original dataset contained information on 3 million used cars. The provided dataset contains information on 426K cars to ensure speed of processing.  Your goal is to understand what factors make a car more or less expensive.  As a result of your analysis, you should provide clear recommendations to your client -- a used car dealership -- as to what consumers value in a used car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CRISP-DM Framework\n",
    "\n",
    "<center>\n",
    "    <img src = images/crisp.png width = 50%/>\n",
    "</center>\n",
    "\n",
    "\n",
    "To frame the task, throughout our practical applications, we will refer back to a standard process in industry for data projects called CRISP-DM.  This process provides a framework for working through a data problem.  Your first step in this application will be to read through a brief overview of CRISP-DM [here](https://mo-pcco.s3.us-east-1.amazonaws.com/BH-PCMLAI/module_11/readings_starter.zip).  After reading the overview, answer the questions below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business Understanding\n",
    "\n",
    "From a business perspective, we are tasked with identifying key drivers for used car prices.  In the CRISP-DM overview, we are asked to convert this business framing to a data problem definition.  Using a few sentences, reframe the task as a data task with the appropriate technical vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_problem_definition = \"\"\"\n",
    "This is a supervised regression problem, with a continuous target variable, price.\n",
    "After the features are standardized, linear, ridge, and lasso regression models \n",
    "will be used to predict the price. After selecting the best model, the\n",
    "coefficients will be analyzed to produce a set of features ranked by predictive\n",
    "power, indicating what drives the price of a car.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Understanding\n",
    "\n",
    "After considering the business understanding, we want to get familiar with our data.  Write down some steps that you would take to get to know the dataset and identify any quality issues within.  Take time to get to know the dataset and explore what information it contains and how this could be used to inform your business understanding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATASET OVERVIEW\n",
      "================================================================================\n",
      "\n",
      "Dataset Shape: 426,880 rows × 18 columns\n",
      "\n",
      "Column Names:\n",
      "   1. id\n",
      "   2. region\n",
      "   3. price\n",
      "   4. year\n",
      "   5. manufacturer\n",
      "   6. model\n",
      "   7. condition\n",
      "   8. cylinders\n",
      "   9. fuel\n",
      "  10. odometer\n",
      "  11. title_status\n",
      "  12. transmission\n",
      "  13. VIN\n",
      "  14. drive\n",
      "  15. size\n",
      "  16. type\n",
      "  17. paint_color\n",
      "  18. state\n",
      "\n",
      "================================================================================\n",
      "DATA TYPES\n",
      "================================================================================\n",
      "id                int64\n",
      "region           object\n",
      "price             int64\n",
      "year            float64\n",
      "manufacturer     object\n",
      "model            object\n",
      "condition        object\n",
      "cylinders        object\n",
      "fuel             object\n",
      "odometer        float64\n",
      "title_status     object\n",
      "transmission     object\n",
      "VIN              object\n",
      "drive            object\n",
      "size             object\n",
      "type             object\n",
      "paint_color      object\n",
      "state            object\n",
      "dtype: object\n",
      "\n",
      "================================================================================\n",
      "BASIC STATISTICS\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>year</th>\n",
       "      <th>odometer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4.268800e+05</td>\n",
       "      <td>4.268800e+05</td>\n",
       "      <td>425675.000000</td>\n",
       "      <td>4.224800e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>7.311487e+09</td>\n",
       "      <td>7.519903e+04</td>\n",
       "      <td>2011.235191</td>\n",
       "      <td>9.804333e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.473170e+06</td>\n",
       "      <td>1.218228e+07</td>\n",
       "      <td>9.452120</td>\n",
       "      <td>2.138815e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.207408e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>7.308143e+09</td>\n",
       "      <td>5.900000e+03</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>3.770400e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.312621e+09</td>\n",
       "      <td>1.395000e+04</td>\n",
       "      <td>2013.000000</td>\n",
       "      <td>8.554800e+04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.315254e+09</td>\n",
       "      <td>2.648575e+04</td>\n",
       "      <td>2017.000000</td>\n",
       "      <td>1.335425e+05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.317101e+09</td>\n",
       "      <td>3.736929e+09</td>\n",
       "      <td>2022.000000</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price           year      odometer\n",
       "count  4.268800e+05  4.268800e+05  425675.000000  4.224800e+05\n",
       "mean   7.311487e+09  7.519903e+04    2011.235191  9.804333e+04\n",
       "std    4.473170e+06  1.218228e+07       9.452120  2.138815e+05\n",
       "min    7.207408e+09  0.000000e+00    1900.000000  0.000000e+00\n",
       "25%    7.308143e+09  5.900000e+03    2008.000000  3.770400e+04\n",
       "50%    7.312621e+09  1.395000e+04    2013.000000  8.554800e+04\n",
       "75%    7.315254e+09  2.648575e+04    2017.000000  1.335425e+05\n",
       "max    7.317101e+09  3.736929e+09    2022.000000  1.000000e+07"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the vehicles dataset\n",
    "vehicles = pd.read_csv('data/vehicles.csv')\n",
    "\n",
    "# Basic dataset information\n",
    "print(\"=\" * 80)\n",
    "print(\"DATASET OVERVIEW\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nDataset Shape: {vehicles.shape[0]:,} rows × {vehicles.shape[1]} columns\")\n",
    "print(f\"\\nColumn Names:\")\n",
    "for i, col in enumerate(vehicles.columns, 1):\n",
    "    print(f\"  {i:2d}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"DATA TYPES\")\n",
    "print(\"=\" * 80)\n",
    "print(vehicles.dtypes)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"BASIC STATISTICS\")\n",
    "print(\"=\" * 80)\n",
    "display(vehicles.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MISSING VALUES ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Total missing values: 1,215,152\n",
      "\n",
      "Columns with missing values (14):\n",
      "              Missing Count  Missing Percentage\n",
      "size                 306361               71.77\n",
      "cylinders            177678               41.62\n",
      "condition            174104               40.79\n",
      "VIN                  161042               37.73\n",
      "drive                130567               30.59\n",
      "paint_color          130203               30.50\n",
      "type                  92858               21.75\n",
      "manufacturer          17646                4.13\n",
      "title_status           8242                1.93\n",
      "model                  5277                1.24\n",
      "odometer               4400                1.03\n",
      "fuel                   3013                0.71\n",
      "transmission           2556                0.60\n",
      "year                   1205                0.28\n",
      "\n",
      "================================================================================\n",
      "COMPLETE CASES\n",
      "================================================================================\n",
      "Rows with complete data: 34,868 (8.17%)\n"
     ]
    }
   ],
   "source": [
    "# Missing values analysis\n",
    "print(\"=\" * 80)\n",
    "print(\"MISSING VALUES ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "missing_data = vehicles.isnull().sum()\n",
    "missing_pct = (missing_data / len(vehicles) * 100).round(2)\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Count': missing_data,\n",
    "    'Missing Percentage': missing_pct\n",
    "})\n",
    "missing_df = missing_df[missing_df['Missing Count'] > 0].sort_values('Missing Count', ascending=False)\n",
    "print(f\"\\nTotal missing values: {vehicles.isnull().sum().sum():,}\")\n",
    "print(f\"\\nColumns with missing values ({len(missing_df)}):\")\n",
    "print(missing_df.to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"COMPLETE CASES\")\n",
    "print(\"=\" * 80)\n",
    "complete_cases = vehicles.dropna()\n",
    "print(f\"Rows with complete data: {len(complete_cases):,} ({len(complete_cases)/len(vehicles)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "CATEGORICAL VARIABLES SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Categorical columns (14): ['region', 'manufacturer', 'model', 'condition', 'cylinders', 'fuel', 'title_status', 'transmission', 'VIN', 'drive', 'size', 'type', 'paint_color', 'state']\n",
      "\n",
      "REGION:\n",
      "  Unique values: 404\n",
      "  Top 10 values:\n",
      "    columbus: 3,608 (0.85%)\n",
      "    jacksonville: 3,562 (0.83%)\n",
      "    spokane / coeur d'alene: 2,988 (0.70%)\n",
      "    eugene: 2,985 (0.70%)\n",
      "    fresno / madera: 2,983 (0.70%)\n",
      "    orlando: 2,983 (0.70%)\n",
      "    bend: 2,982 (0.70%)\n",
      "    omaha / council bluffs: 2,982 (0.70%)\n",
      "    new hampshire: 2,981 (0.70%)\n",
      "    kennewick-pasco-richland: 2,981 (0.70%)\n",
      "\n",
      "MANUFACTURER:\n",
      "  Unique values: 42\n",
      "  Top 10 values:\n",
      "    ford: 70,985 (16.63%)\n",
      "    chevrolet: 55,064 (12.90%)\n",
      "    toyota: 34,202 (8.01%)\n",
      "    honda: 21,269 (4.98%)\n",
      "    nissan: 19,067 (4.47%)\n",
      "    jeep: 19,014 (4.45%)\n",
      "    ram: 18,342 (4.30%)\n",
      "    nan: 17,646 (4.13%)\n",
      "    gmc: 16,785 (3.93%)\n",
      "    bmw: 14,699 (3.44%)\n",
      "\n",
      "MODEL:\n",
      "  Unique values: 29649\n",
      "  Top 10 values:\n",
      "    f-150: 8,009 (1.88%)\n",
      "    nan: 5,277 (1.24%)\n",
      "    silverado 1500: 5,140 (1.20%)\n",
      "    1500: 4,211 (0.99%)\n",
      "    camry: 3,135 (0.73%)\n",
      "    silverado: 3,023 (0.71%)\n",
      "    accord: 2,969 (0.70%)\n",
      "    wrangler: 2,848 (0.67%)\n",
      "    civic: 2,799 (0.66%)\n",
      "    altima: 2,779 (0.65%)\n",
      "\n",
      "CONDITION:\n",
      "  Unique values: 6\n",
      "  Top 10 values:\n",
      "    nan: 174,104 (40.79%)\n",
      "    good: 121,456 (28.45%)\n",
      "    excellent: 101,467 (23.77%)\n",
      "    like new: 21,178 (4.96%)\n",
      "    fair: 6,769 (1.59%)\n",
      "    new: 1,305 (0.31%)\n",
      "    salvage: 601 (0.14%)\n",
      "\n",
      "CYLINDERS:\n",
      "  Unique values: 8\n",
      "  Top 10 values:\n",
      "    nan: 177,678 (41.62%)\n",
      "    6 cylinders: 94,169 (22.06%)\n",
      "    4 cylinders: 77,642 (18.19%)\n",
      "    8 cylinders: 72,062 (16.88%)\n",
      "    5 cylinders: 1,712 (0.40%)\n",
      "    10 cylinders: 1,455 (0.34%)\n",
      "    other: 1,298 (0.30%)\n",
      "    3 cylinders: 655 (0.15%)\n",
      "    12 cylinders: 209 (0.05%)\n",
      "\n",
      "FUEL:\n",
      "  Unique values: 5\n",
      "  Top 10 values:\n",
      "    gas: 356,209 (83.44%)\n",
      "    other: 30,728 (7.20%)\n",
      "    diesel: 30,062 (7.04%)\n",
      "    hybrid: 5,170 (1.21%)\n",
      "    nan: 3,013 (0.71%)\n",
      "    electric: 1,698 (0.40%)\n",
      "\n",
      "TITLE_STATUS:\n",
      "  Unique values: 6\n",
      "  Top 10 values:\n",
      "    clean: 405,117 (94.90%)\n",
      "    nan: 8,242 (1.93%)\n",
      "    rebuilt: 7,219 (1.69%)\n",
      "    salvage: 3,868 (0.91%)\n",
      "    lien: 1,422 (0.33%)\n",
      "    missing: 814 (0.19%)\n",
      "    parts only: 198 (0.05%)\n",
      "\n",
      "TRANSMISSION:\n",
      "  Unique values: 3\n",
      "  Top 10 values:\n",
      "    automatic: 336,524 (78.83%)\n",
      "    other: 62,682 (14.68%)\n",
      "    manual: 25,118 (5.88%)\n",
      "    nan: 2,556 (0.60%)\n",
      "\n",
      "DRIVE:\n",
      "  Unique values: 3\n",
      "  Top 10 values:\n",
      "    4wd: 131,904 (30.90%)\n",
      "    nan: 130,567 (30.59%)\n",
      "    fwd: 105,517 (24.72%)\n",
      "    rwd: 58,892 (13.80%)\n",
      "\n",
      "SIZE:\n",
      "  Unique values: 4\n",
      "  Top 10 values:\n",
      "    nan: 306,361 (71.77%)\n",
      "    full-size: 63,465 (14.87%)\n",
      "    mid-size: 34,476 (8.08%)\n",
      "    compact: 19,384 (4.54%)\n",
      "    sub-compact: 3,194 (0.75%)\n",
      "\n",
      "TYPE:\n",
      "  Unique values: 13\n",
      "  Top 10 values:\n",
      "    nan: 92,858 (21.75%)\n",
      "    sedan: 87,056 (20.39%)\n",
      "    SUV: 77,284 (18.10%)\n",
      "    pickup: 43,510 (10.19%)\n",
      "    truck: 35,279 (8.26%)\n",
      "    other: 22,110 (5.18%)\n",
      "    coupe: 19,204 (4.50%)\n",
      "    hatchback: 16,598 (3.89%)\n",
      "    wagon: 10,751 (2.52%)\n",
      "    van: 8,548 (2.00%)\n",
      "\n",
      "PAINT_COLOR:\n",
      "  Unique values: 12\n",
      "  Top 10 values:\n",
      "    nan: 130,203 (30.50%)\n",
      "    white: 79,285 (18.57%)\n",
      "    black: 62,861 (14.73%)\n",
      "    silver: 42,970 (10.07%)\n",
      "    blue: 31,223 (7.31%)\n",
      "    red: 30,473 (7.14%)\n",
      "    grey: 24,416 (5.72%)\n",
      "    green: 7,343 (1.72%)\n",
      "    custom: 6,700 (1.57%)\n",
      "    brown: 6,593 (1.54%)\n",
      "\n",
      "STATE:\n",
      "  Unique values: 51\n",
      "  Top 10 values:\n",
      "    ca: 50,614 (11.86%)\n",
      "    fl: 28,511 (6.68%)\n",
      "    tx: 22,945 (5.38%)\n",
      "    ny: 19,386 (4.54%)\n",
      "    oh: 17,696 (4.15%)\n",
      "    or: 17,104 (4.01%)\n",
      "    mi: 16,900 (3.96%)\n",
      "    nc: 15,277 (3.58%)\n",
      "    wa: 13,861 (3.25%)\n",
      "    pa: 13,753 (3.22%)\n"
     ]
    }
   ],
   "source": [
    "# Categorical variables summary\n",
    "print(\"=\" * 80)\n",
    "print(\"CATEGORICAL VARIABLES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "categorical_cols = vehicles.select_dtypes(include=['object']).columns\n",
    "print(f\"\\nCategorical columns ({len(categorical_cols)}): {list(categorical_cols)}\")\n",
    "\n",
    "for col in categorical_cols:\n",
    "    if col != 'VIN':  # Skip VIN as it's likely unique identifiers\n",
    "        print(f\"\\n{col.upper()}:\")\n",
    "        value_counts = vehicles[col].value_counts(dropna=False)\n",
    "        print(f\"  Unique values: {vehicles[col].nunique()}\")\n",
    "        print(f\"  Top 10 values:\")\n",
    "        for val, count in value_counts.head(10).items():\n",
    "            pct = (count / len(vehicles) * 100)\n",
    "            print(f\"    {val}: {count:,} ({pct:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NUMERICAL VARIABLES SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Numerical columns (4): ['id', 'price', 'year', 'odometer']\n",
      "\n",
      "Detailed Statistics:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>426880.0</td>\n",
       "      <td>7.311487e+09</td>\n",
       "      <td>4.473170e+06</td>\n",
       "      <td>7.207408e+09</td>\n",
       "      <td>7.308143e+09</td>\n",
       "      <td>7.312621e+09</td>\n",
       "      <td>7.315254e+09</td>\n",
       "      <td>7.317101e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>426880.0</td>\n",
       "      <td>7.519903e+04</td>\n",
       "      <td>1.218228e+07</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>5.900000e+03</td>\n",
       "      <td>1.395000e+04</td>\n",
       "      <td>2.648575e+04</td>\n",
       "      <td>3.736929e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>425675.0</td>\n",
       "      <td>2.011235e+03</td>\n",
       "      <td>9.452120e+00</td>\n",
       "      <td>1.900000e+03</td>\n",
       "      <td>2.008000e+03</td>\n",
       "      <td>2.013000e+03</td>\n",
       "      <td>2.017000e+03</td>\n",
       "      <td>2.022000e+03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>odometer</th>\n",
       "      <td>422480.0</td>\n",
       "      <td>9.804333e+04</td>\n",
       "      <td>2.138815e+05</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>3.770400e+04</td>\n",
       "      <td>8.554800e+04</td>\n",
       "      <td>1.335425e+05</td>\n",
       "      <td>1.000000e+07</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             count          mean           std           min           25%  \\\n",
       "id        426880.0  7.311487e+09  4.473170e+06  7.207408e+09  7.308143e+09   \n",
       "price     426880.0  7.519903e+04  1.218228e+07  0.000000e+00  5.900000e+03   \n",
       "year      425675.0  2.011235e+03  9.452120e+00  1.900000e+03  2.008000e+03   \n",
       "odometer  422480.0  9.804333e+04  2.138815e+05  0.000000e+00  3.770400e+04   \n",
       "\n",
       "                   50%           75%           max  \n",
       "id        7.312621e+09  7.315254e+09  7.317101e+09  \n",
       "price     1.395000e+04  2.648575e+04  3.736929e+09  \n",
       "year      2.013000e+03  2.017000e+03  2.022000e+03  \n",
       "odometer  8.554800e+04  1.335425e+05  1.000000e+07  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Numerical variables summary\n",
    "print(\"=\" * 80)\n",
    "print(\"NUMERICAL VARIABLES SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "numerical_cols = vehicles.select_dtypes(include=[np.number]).columns\n",
    "print(f\"\\nNumerical columns ({len(numerical_cols)}): {list(numerical_cols)}\")\n",
    "\n",
    "print(\"\\nDetailed Statistics:\")\n",
    "display(vehicles[numerical_cols].describe().T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA QUALITY SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Total Records: 426,880\n",
      "Total Columns: 18\n",
      "Total Missing Values: 1,215,152\n",
      "Percentage of Missing Data: 15.81%\n",
      "\n",
      "Duplicate Records: 0\n",
      "\n",
      "Potential Data Quality Issues:\n",
      "  ⚠️  High percentage of zero prices: 7.71%\n"
     ]
    }
   ],
   "source": [
    "# Data quality summary\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA QUALITY SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nTotal Records: {len(vehicles):,}\")\n",
    "print(f\"Total Columns: {len(vehicles.columns)}\")\n",
    "print(f\"Total Missing Values: {vehicles.isnull().sum().sum():,}\")\n",
    "print(f\"Percentage of Missing Data: {(vehicles.isnull().sum().sum() / (len(vehicles) * len(vehicles.columns)) * 100):.2f}%\")\n",
    "\n",
    "print(f\"\\nDuplicate Records: {vehicles.duplicated().sum():,}\")\n",
    "if vehicles.duplicated().sum() > 0:\n",
    "    print(f\"Percentage Duplicates: {(vehicles.duplicated().sum() / len(vehicles) * 100):.2f}%\")\n",
    "\n",
    "# Check for potential issues\n",
    "print(\"\\nPotential Data Quality Issues:\")\n",
    "if 'price' in vehicles.columns:\n",
    "    zero_price_pct = (vehicles['price'] == 0).sum() / len(vehicles) * 100\n",
    "    if zero_price_pct > 1:\n",
    "        print(f\"  ⚠️  High percentage of zero prices: {zero_price_pct:.2f}%\")\n",
    "    \n",
    "if 'year' in vehicles.columns:\n",
    "    if vehicles['year'].notna().sum() > 0:\n",
    "        current_year = pd.Timestamp.now().year\n",
    "        future_years = (vehicles['year'] > current_year).sum()\n",
    "        very_old_years = (vehicles['year'] < 1900).sum()\n",
    "        if future_years > 0:\n",
    "            print(f\"  ⚠️  Future years detected: {future_years:,} records\")\n",
    "        if very_old_years > 0:\n",
    "            print(f\"  ⚠️  Very old years detected: {very_old_years:,} records\")\n",
    "\n",
    "if 'odometer' in vehicles.columns:\n",
    "    if vehicles['odometer'].notna().sum() > 0:\n",
    "        negative_odometer = (vehicles['odometer'] < 0).sum()\n",
    "        if negative_odometer > 0:\n",
    "            print(f\"  ⚠️  Negative odometer values: {negative_odometer:,} records\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "\n",
    "After our initial exploration and fine-tuning of the business understanding, it is time to construct our final dataset prior to modeling.  Here, we want to make sure to handle any integrity issues and cleaning, the engineering of new features, any transformations that we believe should happen (scaling, logarithms, normalization, etc.), and general preparation for modeling with `sklearn`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "DATA CLEANING PROCESS\n",
      "================================================================================\n",
      "\n",
      "Initial shape: (426880, 18)\n",
      "\n",
      "After dropping 'size', 'VIN', and 'state' columns: (426880, 15)\n",
      "After dropping rows with null 'model', 'odometer', or 'year': (416149, 15)\n",
      "  Rows dropped: 10,731 (2.51%)\n",
      "\n",
      "================================================================================\n",
      "FILLING PAINT_COLOR AND CONDITION\n",
      "================================================================================\n",
      "\n",
      "After filling 'paint_color' and 'condition' nulls with 'unknown':\n",
      "  paint_color nulls: 0\n",
      "  condition nulls: 0\n"
     ]
    }
   ],
   "source": [
    "# Start with a copy of the original dataset\n",
    "vehicles_clean = vehicles.copy()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"DATA CLEANING PROCESS\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nInitial shape: {vehicles_clean.shape}\")\n",
    "\n",
    "# Step 1: Drop 'size', 'VIN', and 'state' columns\n",
    "vehicles_clean = vehicles_clean.drop(columns=['size', 'VIN', 'state'])\n",
    "print(f\"\\nAfter dropping 'size', 'VIN', and 'state' columns: {vehicles_clean.shape}\")\n",
    "\n",
    "# Step 2: Drop rows where 'model' or 'odometer' is null\n",
    "initial_rows = len(vehicles_clean)\n",
    "vehicles_clean = vehicles_clean.dropna(subset=['model', 'odometer', 'year'])\n",
    "rows_dropped = initial_rows - len(vehicles_clean)\n",
    "print(f\"After dropping rows with null 'model', 'odometer', or 'year': {vehicles_clean.shape}\")\n",
    "print(f\"  Rows dropped: {rows_dropped:,} ({rows_dropped/initial_rows*100:.2f}%)\\n\")\n",
    "\n",
    "# Step 3: Set 'paint_color' and 'condition' null values to 'unknown'\n",
    "vehicles_clean['paint_color'] = vehicles_clean['paint_color'].fillna('unknown')\n",
    "vehicles_clean['condition'] = vehicles_clean['condition'].fillna('unknown')\n",
    "print(\"=\" * 80)\n",
    "print(\"FILLING PAINT_COLOR AND CONDITION\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAfter filling 'paint_color' and 'condition' nulls with 'unknown':\")\n",
    "print(f\"  paint_color nulls: {vehicles_clean['paint_color'].isnull().sum()}\")\n",
    "print(f\"  condition nulls: {vehicles_clean['condition'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 4: CONTEXTUAL IMPUTATION\n",
      "================================================================================\n",
      "\n",
      "4a. Imputing manufacturer from model...\n",
      "  Manufacturers still missing: 15547\n",
      "\n",
      "4b. Imputing fuel from model...\n",
      "  Fuel still missing: 1379\n",
      "\n",
      "4c. Imputing type from model...\n",
      "  Type still missing: 10098\n",
      "\n",
      "4d. Imputing cylinders from model and year...\n",
      "  Cylinders still missing: 56808\n",
      "\n",
      "4e. Imputing transmission from model and year...\n",
      "  Transmission still missing: 159\n",
      "\n",
      "4f. Imputing drive from model and year...\n",
      "  Drive still missing: 38468\n",
      "\n",
      "================================================================================\n",
      "STEP 4 COMPLETE: SUMMARY OF MISSING VALUES\n",
      "================================================================================\n",
      "\n",
      "Remaining missing values:\n",
      "  cylinders: 56,808 (13.65%)\n",
      "  drive: 38,468 (9.24%)\n",
      "  manufacturer: 15,547 (3.74%)\n",
      "  type: 10,098 (2.43%)\n",
      "  title_status: 7,327 (1.76%)\n",
      "  fuel: 1,379 (0.33%)\n",
      "  transmission: 159 (0.04%)\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Impute missing values contextually\n",
    "\n",
    "# Manufacturer, fuel, and type can be imputed from the model \n",
    "# Cylinders, transmission, and drive can be imputed from model and year\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 4: CONTEXTUAL IMPUTATION\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 4a. Impute manufacturer from model\n",
    "print(\"\\n4a. Imputing manufacturer from model...\")\n",
    "model_to_manufacturer = vehicles_clean[vehicles_clean['manufacturer'].notna()] \\\n",
    "    .groupby('model')['manufacturer'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]).to_dict()\n",
    "vehicles_clean['manufacturer'] = vehicles_clean['manufacturer'].fillna(\n",
    "    vehicles_clean['model'].map(model_to_manufacturer)\n",
    ")\n",
    "print(f\"  Manufacturers still missing: {vehicles_clean['manufacturer'].isnull().sum()}\")\n",
    "\n",
    "# 4b. Impute fuel from model\n",
    "print(\"\\n4b. Imputing fuel from model...\")\n",
    "model_to_fuel = vehicles_clean[vehicles_clean['fuel'].notna()] \\\n",
    "    .groupby('model')['fuel'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]).to_dict()\n",
    "vehicles_clean['fuel'] = vehicles_clean['fuel'].fillna(\n",
    "    vehicles_clean['model'].map(model_to_fuel)\n",
    ")\n",
    "print(f\"  Fuel still missing: {vehicles_clean['fuel'].isnull().sum()}\")\n",
    "\n",
    "# 4c. Impute type from model\n",
    "print(\"\\n4c. Imputing type from model...\")\n",
    "model_to_type = vehicles_clean[vehicles_clean['type'].notna()] \\\n",
    "    .groupby('model')['type'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0]).to_dict()\n",
    "vehicles_clean['type'] = vehicles_clean['type'].fillna(\n",
    "    vehicles_clean['model'].map(model_to_type)\n",
    ")\n",
    "print(f\"  Type still missing: {vehicles_clean['type'].isnull().sum()}\")\n",
    "\n",
    "# 4d. Impute cylinders from model and year\n",
    "print(\"\\n4d. Imputing cylinders from model and year...\")\n",
    "model_year_to_cylinders = vehicles_clean[vehicles_clean['cylinders'].notna()] \\\n",
    "    .groupby(['model', 'year'])['cylinders'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0])\n",
    "model_year_to_cylinders_df = model_year_to_cylinders.reset_index()\n",
    "model_year_to_cylinders_df.columns = ['model', 'year', 'cylinders_imputed']\n",
    "vehicles_clean = vehicles_clean.merge(model_year_to_cylinders_df, on=['model', 'year'], how='left')\n",
    "vehicles_clean['cylinders'] = vehicles_clean['cylinders'].fillna(vehicles_clean['cylinders_imputed'])\n",
    "vehicles_clean = vehicles_clean.drop(columns=['cylinders_imputed'])\n",
    "print(f\"  Cylinders still missing: {vehicles_clean['cylinders'].isnull().sum()}\")\n",
    "\n",
    "# 4e. Impute transmission from model and year\n",
    "print(\"\\n4e. Imputing transmission from model and year...\")\n",
    "model_year_to_transmission = vehicles_clean[vehicles_clean['transmission'].notna()] \\\n",
    "    .groupby(['model', 'year'])['transmission'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0])\n",
    "model_year_to_transmission_df = model_year_to_transmission.reset_index()\n",
    "model_year_to_transmission_df.columns = ['model', 'year', 'transmission_imputed']\n",
    "vehicles_clean = vehicles_clean.merge(model_year_to_transmission_df, on=['model', 'year'], how='left')\n",
    "vehicles_clean['transmission'] = vehicles_clean['transmission'].fillna(vehicles_clean['transmission_imputed'])\n",
    "vehicles_clean = vehicles_clean.drop(columns=['transmission_imputed'])\n",
    "print(f\"  Transmission still missing: {vehicles_clean['transmission'].isnull().sum()}\")\n",
    "\n",
    "# 4f. Impute drive from model and year\n",
    "print(\"\\n4f. Imputing drive from model and year...\")\n",
    "model_year_to_drive = vehicles_clean[vehicles_clean['drive'].notna()] \\\n",
    "    .groupby(['model', 'year'])['drive'].agg(lambda x: x.mode().iloc[0] if not x.mode().empty else x.iloc[0])\n",
    "model_year_to_drive_df = model_year_to_drive.reset_index()\n",
    "model_year_to_drive_df.columns = ['model', 'year', 'drive_imputed']\n",
    "vehicles_clean = vehicles_clean.merge(model_year_to_drive_df, on=['model', 'year'], how='left')\n",
    "vehicles_clean['drive'] = vehicles_clean['drive'].fillna(vehicles_clean['drive_imputed'])\n",
    "vehicles_clean = vehicles_clean.drop(columns=['drive_imputed'])\n",
    "print(f\"  Drive still missing: {vehicles_clean['drive'].isnull().sum()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"STEP 4 COMPLETE: SUMMARY OF MISSING VALUES\")\n",
    "print(\"=\" * 80)\n",
    "missing_after = vehicles_clean.isnull().sum()\n",
    "missing_after = missing_after[missing_after > 0].sort_values(ascending=False)\n",
    "if len(missing_after) > 0:\n",
    "    print(\"\\nRemaining missing values:\")\n",
    "    for col, count in missing_after.items():\n",
    "        pct = (count / len(vehicles_clean) * 100)\n",
    "        print(f\"  {col}: {count:,} ({pct:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\nNo missing values remaining!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze numeric features for skew\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "STEP 5: FINAL DATA CLEANING - DROP ROWS WITH MISSING VALUES\n",
      "================================================================================\n",
      "\n",
      "Rows before dropping NaNs: 416,149\n",
      "Features with missing values: ['manufacturer', 'cylinders', 'fuel', 'title_status', 'transmission', 'drive', 'type']\n",
      "Rows after dropping NaNs: 329,600\n",
      "Total rows dropped: 86,549 (20.80%)\n",
      "\n",
      "================================================================================\n",
      "REMOVING INVALID PRICE VALUES (price = 0 or price > $200,000)\n",
      "================================================================================\n",
      "\n",
      "Rows before filtering: 329,600\n",
      "Rows with price = 0: 25,684\n",
      "Rows with price > $200,000: 47\n",
      "\n",
      "Rows after filtering: 303,869\n",
      "Total rows dropped: 25,731 (7.81%)\n",
      "  - Zero prices dropped: 25,684\n",
      "  - Extreme prices dropped: 47\n",
      "\n",
      "================================================================================\n",
      "SHAPE COMPARISON\n",
      "================================================================================\n",
      "\n",
      "Original dataset (vehicles):     426,880 rows × 18 columns\n",
      "After Steps 1-4 (vehicles_clean): 416,149 rows × 15 columns\n",
      "Final dataset (vehicles_final):   303,869 rows × 15 columns\n",
      "\n",
      "Total rows dropped from original: 123,011 (28.82%)\n",
      "\n",
      "================================================================================\n",
      "ROWS DROPPED BY FEATURE (features NOT imputed or dropped in previous steps)\n",
      "================================================================================\n",
      "\n",
      "Rows dropped due to missing values in unhandled features:\n",
      "  title_status: 7,327 rows (1.76%)\n",
      "\n",
      "================================================================================\n",
      "TOTAL MISSING VALUES BY FEATURE (before dropping)\n",
      "================================================================================\n",
      "\n",
      "All features with missing values before Step 5:\n",
      "  manufacturer: 15,547 rows (3.74%) [✓ handled]\n",
      "  cylinders: 56,808 rows (13.65%) [✓ handled]\n",
      "  fuel: 1,379 rows (0.33%) [✓ handled]\n",
      "  title_status: 7,327 rows (1.76%) [✗ not handled]\n",
      "  transmission: 159 rows (0.04%) [✓ handled]\n",
      "  drive: 38,468 rows (9.24%) [✓ handled]\n",
      "  type: 10,098 rows (2.43%) [✓ handled]\n",
      "\n",
      "================================================================================\n",
      "FINAL DATASET VERIFICATION\n",
      "================================================================================\n",
      "\n",
      "✓ Final dataset has no missing values - ready for modeling!\n",
      "  Final shape: (303869, 15)\n"
     ]
    }
   ],
   "source": [
    "# STEP 5: Drop remaining rows with NaNs and analyze the impact\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"STEP 5: FINAL DATA CLEANING - DROP ROWS WITH MISSING VALUES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# Store initial state for comparison\n",
    "rows_before = len(vehicles_clean)\n",
    "\n",
    "# Identify features that still have missing values\n",
    "# Features imputed in Step 4: manufacturer, fuel, type, cylinders, transmission, drive\n",
    "# Features filled in Step 3: paint_color, condition\n",
    "# Features used for dropping in Step 2: model, odometer, year\n",
    "remaining_missing = vehicles_clean.isnull().sum()\n",
    "features_with_missing = remaining_missing[remaining_missing > 0].index.tolist()\n",
    "\n",
    "print(f\"\\nRows before dropping NaNs: {rows_before:,}\")\n",
    "print(f\"Features with missing values: {features_with_missing}\")\n",
    "\n",
    "# Drop rows with any remaining missing values\n",
    "vehicles_final = vehicles_clean.dropna()\n",
    "rows_after = len(vehicles_final)\n",
    "rows_dropped = rows_before - rows_after\n",
    "\n",
    "print(f\"Rows after dropping NaNs: {rows_after:,}\")\n",
    "print(f\"Total rows dropped: {rows_dropped:,} ({rows_dropped/rows_before*100:.2f}%)\")\n",
    "\n",
    "# Drop rows with zero prices and prices larger than 200,000\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"REMOVING INVALID PRICE VALUES (price = 0 or price > $200,000)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "rows_before_price_filter = len(vehicles_final)\n",
    "\n",
    "# Check for zero prices\n",
    "zero_price_rows = vehicles_final[vehicles_final['price'] == 0]\n",
    "zero_price_count = len(zero_price_rows)\n",
    "\n",
    "# Check for extreme prices\n",
    "price_threshold = 200_000\n",
    "extreme_price_rows = vehicles_final[vehicles_final['price'] > price_threshold]\n",
    "extreme_price_count = len(extreme_price_rows)\n",
    "\n",
    "print(f\"\\nRows before filtering: {rows_before_price_filter:,}\")\n",
    "print(f\"Rows with price = 0: {zero_price_count:,}\")\n",
    "print(f\"Rows with price > ${price_threshold:,}: {extreme_price_count:,}\")\n",
    "\n",
    "# Drop rows with zero prices and extreme prices\n",
    "vehicles_final = vehicles_final[(vehicles_final['price'] > 0) & (vehicles_final['price'] <= price_threshold)]\n",
    "rows_after_price_filter = len(vehicles_final)\n",
    "rows_dropped_price = rows_before_price_filter - rows_after_price_filter\n",
    "\n",
    "if rows_dropped_price > 0:\n",
    "    print(f\"\\nRows after filtering: {rows_after_price_filter:,}\")\n",
    "    print(f\"Total rows dropped: {rows_dropped_price:,} ({rows_dropped_price/rows_before_price_filter*100:.2f}%)\")\n",
    "    if zero_price_count > 0:\n",
    "        print(f\"  - Zero prices dropped: {zero_price_count:,}\")\n",
    "    if extreme_price_count > 0:\n",
    "        print(f\"  - Extreme prices dropped: {extreme_price_count:,}\")\n",
    "else:\n",
    "    print(\"\\nNo invalid price values found - no filtering needed.\")\n",
    "\n",
    "# Compare shapes\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"SHAPE COMPARISON\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nOriginal dataset (vehicles):     {vehicles.shape[0]:,} rows × {vehicles.shape[1]} columns\")\n",
    "print(f\"After Steps 1-4 (vehicles_clean): {vehicles_clean.shape[0]:,} rows × {vehicles_clean.shape[1]} columns\")\n",
    "print(f\"Final dataset (vehicles_final):   {vehicles_final.shape[0]:,} rows × {vehicles_final.shape[1]} columns\")\n",
    "print(f\"\\nTotal rows dropped from original: {vehicles.shape[0] - vehicles_final.shape[0]:,} ({(vehicles.shape[0] - vehicles_final.shape[0])/vehicles.shape[0]*100:.2f}%)\")\n",
    "\n",
    "# Count rows dropped for each feature that was NOT imputed or dropped in previous steps\n",
    "# Features handled in previous steps:\n",
    "# Step 4 (imputed): manufacturer, fuel, type, cylinders, transmission, drive\n",
    "# Step 3 (filled): paint_color, condition\n",
    "# Step 2 (dropped rows with missing): model, odometer, year\n",
    "handled_features = {'manufacturer', 'fuel', 'type', 'cylinders', 'transmission', 'drive', \n",
    "                    'paint_color', 'condition', 'model', 'odometer', 'year'}\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ROWS DROPPED BY FEATURE (features NOT imputed or dropped in previous steps)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "unhandled_features_with_missing = [f for f in features_with_missing if f not in handled_features]\n",
    "if len(unhandled_features_with_missing) > 0:\n",
    "    print(\"\\nRows dropped due to missing values in unhandled features:\")\n",
    "    for feature in unhandled_features_with_missing:\n",
    "        missing_count = vehicles_clean[feature].isnull().sum()\n",
    "        print(f\"  {feature}: {missing_count:,} rows ({missing_count/rows_before*100:.2f}%)\")\n",
    "else:\n",
    "    print(\"\\nAll features with missing values were handled in previous steps.\")\n",
    "\n",
    "# Also show total missing per feature for reference\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"TOTAL MISSING VALUES BY FEATURE (before dropping)\")\n",
    "print(\"=\" * 80)\n",
    "if len(features_with_missing) > 0:\n",
    "    print(\"\\nAll features with missing values before Step 5:\")\n",
    "    for feature in features_with_missing:\n",
    "        missing_count = vehicles_clean[feature].isnull().sum()\n",
    "        handled_status = \"✓ handled\" if feature in handled_features else \"✗ not handled\"\n",
    "        print(f\"  {feature}: {missing_count:,} rows ({missing_count/rows_before*100:.2f}%) [{handled_status}]\")\n",
    "\n",
    "# Final verification\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FINAL DATASET VERIFICATION\")\n",
    "print(\"=\" * 80)\n",
    "if vehicles_final.isnull().sum().sum() == 0:\n",
    "    print(\"\\n✓ Final dataset has no missing values - ready for modeling!\")\n",
    "    print(f\"  Final shape: {vehicles_final.shape}\")\n",
    "else:\n",
    "    remaining = vehicles_final.isnull().sum()\n",
    "    remaining = remaining[remaining > 0]\n",
    "    print(f\"\\n⚠ Warning: {remaining.sum()} missing values still remain in:\")\n",
    "    for col, count in remaining.items():\n",
    "        print(f\"  {col}: {count:,}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling\n",
    "\n",
    "With your (almost?) final dataset in hand, it is now time to build some models.  Here, you should build a number of different regression models with the price as the target.  In building your models, you should explore different parameters and be sure to cross-validate your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training, testing, and validation sets\n",
    "# Only include features that will be used in the preprocessor\n",
    "numeric_features = ['year', 'odometer']\n",
    "categorical_features = ['manufacturer', 'fuel', 'type', 'transmission', 'drive', 'paint_color', 'condition', 'cylinders']\n",
    "\n",
    "# Select only the features we'll use for modeling\n",
    "feature_columns = numeric_features + categorical_features\n",
    "X = vehicles_final[feature_columns]\n",
    "# Use log transform of price as target variable\n",
    "y = np.log1p(vehicles_final['price'])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the preprocessing steps\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numeric_features),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_features)\n",
    "    ],\n",
    "    remainder='drop'  # Drop any remaining columns (shouldn't be any since X only contains these features)\n",
    ")\n",
    "\n",
    "# Define the models\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Linear Regression (no int)': LinearRegression(fit_intercept=False),\n",
    "    'Ridge (alpha=0.1)': Ridge(alpha=0.1, random_state=42),\n",
    "    'Ridge (alpha=1.0)': Ridge(alpha=1.0, random_state=42),\n",
    "    'Ridge (alpha=10.0)': Ridge(alpha=10.0, random_state=42),\n",
    "    'Lasso (alpha=0.1)': Lasso(alpha=0.1, random_state=42, max_iter=10000),\n",
    "    'Lasso (alpha=1.0)': Lasso(alpha=1.0, random_state=42, max_iter=10000),\n",
    "    'Lasso (alpha=10.0)': Lasso(alpha=10.0, random_state=42, max_iter=10000)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "MODEL EVALUATION RESULTS\n",
      "================================================================================\n",
      "\n",
      "Linear Regression:\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)      MAE ($)      RMSE ($)\n",
      "Training     1.087908    0.57582    1.043028  1.170558e+08  7006.903185  10819.234237\n",
      "Validation   1.086048    0.57601    1.042136  1.131330e+08  6934.109704  10636.400481\n",
      "\n",
      "Linear Regression (no int):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)      MAE ($)      RMSE ($)\n",
      "Training     1.087908    0.57582    1.043028  1.170558e+08  7006.903185  10819.234237\n",
      "Validation   1.086048    0.57601    1.042136  1.131330e+08  6934.109704  10636.400481\n",
      "\n",
      "Ridge (alpha=0.1):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)      MAE ($)      RMSE ($)\n",
      "Training     1.087908   0.575821    1.043028  1.170582e+08  7006.938714  10819.342288\n",
      "Validation   1.086043   0.576010    1.042134  1.131266e+08  6934.081802  10636.099903\n",
      "\n",
      "Ridge (alpha=1.0):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)      MAE ($)      RMSE ($)\n",
      "Training     1.087909   0.575826    1.043029  1.170822e+08  7007.306658  10820.451750\n",
      "Validation   1.086002   0.576007    1.042114  1.130808e+08  6933.854860  10633.947919\n",
      "\n",
      "Ridge (alpha=10.0):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)      MAE ($)      RMSE ($)\n",
      "Training     1.087961   0.575879    1.043054  1.173383e+08  7010.639594  10832.278173\n",
      "Validation   1.085789   0.576019    1.042012  1.130365e+08  6935.092530  10631.864750\n",
      "\n",
      "Lasso (alpha=0.1):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)      MAE ($)      RMSE ($)\n",
      "Training     1.308643   0.724499    1.143959  1.991610e+08  9441.408465  14112.442670\n",
      "Validation   1.306841   0.723187    1.143171  1.916805e+08  9325.338621  13844.874261\n",
      "\n",
      "Lasso (alpha=1.0):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)       MAE ($)      RMSE ($)\n",
      "Training     1.480165   0.834477    1.216620  2.406972e+08  10791.818410  15514.417779\n",
      "Validation   1.479830   0.835184    1.216483  2.328412e+08  10688.126531  15259.136508\n",
      "\n",
      "Lasso (alpha=10.0):\n",
      "            MSE (log)  MAE (log)  RMSE (log)       MSE ($)       MAE ($)      RMSE ($)\n",
      "Training     1.480165   0.834477    1.216620  2.406972e+08  10791.818410  15514.417779\n",
      "Validation   1.479830   0.835184    1.216483  2.328412e+08  10688.126531  15259.136508\n"
     ]
    }
   ],
   "source": [
    "# Setup pipeline and iterate through models\n",
    "results_list = []\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    pipeline = Pipeline([\n",
    "        ('preprocessor', preprocessor),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    \n",
    "    # Training set predictions and metrics (log space)\n",
    "    y_train_pred_log = pipeline.predict(X_train)\n",
    "    train_mse_log = mean_squared_error(y_train, y_train_pred_log)\n",
    "    train_mae_log = mean_absolute_error(y_train, y_train_pred_log)\n",
    "    train_rmse_log = np.sqrt(train_mse_log)\n",
    "    \n",
    "    # Validation set predictions and metrics (log space)\n",
    "    y_val_pred_log = pipeline.predict(X_val)\n",
    "    val_mse_log = mean_squared_error(y_val, y_val_pred_log)\n",
    "    val_mae_log = mean_absolute_error(y_val, y_val_pred_log)\n",
    "    val_rmse_log = np.sqrt(val_mse_log)\n",
    "    \n",
    "    # Convert predictions and actual values back to dollar space\n",
    "    y_train_price = np.expm1(y_train)\n",
    "    y_train_pred_price = np.expm1(y_train_pred_log)\n",
    "    y_val_price = np.expm1(y_val)\n",
    "    y_val_pred_price = np.expm1(y_val_pred_log)\n",
    "    \n",
    "    # Training set predictions and metrics (dollar space)\n",
    "    train_mse_price = mean_squared_error(y_train_price, y_train_pred_price)\n",
    "    train_mae_price = mean_absolute_error(y_train_price, y_train_pred_price)\n",
    "    train_rmse_price = np.sqrt(train_mse_price)\n",
    "    \n",
    "    # Validation set predictions and metrics (dollar space)\n",
    "    val_mse_price = mean_squared_error(y_val_price, y_val_pred_price)\n",
    "    val_mae_price = mean_absolute_error(y_val_price, y_val_pred_price)\n",
    "    val_rmse_price = np.sqrt(val_mse_price)\n",
    "    \n",
    "    # Create DataFrame for this model with both log-space and dollar-space metrics\n",
    "    model_results = pd.DataFrame({\n",
    "        'MSE (log)': [train_mse_log, val_mse_log],\n",
    "        'MAE (log)': [train_mae_log, val_mae_log],\n",
    "        'RMSE (log)': [train_rmse_log, val_rmse_log],\n",
    "        'MSE ($)': [train_mse_price, val_mse_price],\n",
    "        'MAE ($)': [train_mae_price, val_mae_price],\n",
    "        'RMSE ($)': [train_rmse_price, val_rmse_price]\n",
    "    })\n",
    "    model_results.index = ['Training', 'Validation']\n",
    "    \n",
    "    # Add model name as a title/attribute (store in a tuple with name)\n",
    "    results_list.append((model_name, model_results))\n",
    "\n",
    "# Print all results\n",
    "print(\"=\" * 80)\n",
    "print(\"MODEL EVALUATION RESULTS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for model_name, df in results_list:\n",
    "    print(f\"\\n{model_name}:\")\n",
    "    print(df.to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "With some modeling accomplished, we aim to reflect on what we identify as a high-quality model and what we are able to learn from this.  We should review our business objective and explore how well we can provide meaningful insight into drivers of used car prices.  Your goal now is to distill your findings and determine whether the earlier phases need revisitation and adjustment or if you have information of value to bring back to your client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num__year': np.float64(0.3106547132823581),\n",
       " 'num__odometer': np.float64(-0.10525697440559675),\n",
       " 'cat__manufacturer_acura': np.float64(0.06626919274748912),\n",
       " 'cat__manufacturer_alfa-romeo': np.float64(0.2886201015893709),\n",
       " 'cat__manufacturer_aston-martin': np.float64(0.640902188785006),\n",
       " 'cat__manufacturer_audi': np.float64(0.06649444281550565),\n",
       " 'cat__manufacturer_bmw': np.float64(-0.16169870552829654),\n",
       " 'cat__manufacturer_buick': np.float64(-0.03453452363411558),\n",
       " 'cat__manufacturer_cadillac': np.float64(0.05108897727450687),\n",
       " 'cat__manufacturer_chevrolet': np.float64(-0.0929428239755076),\n",
       " 'cat__manufacturer_chrysler': np.float64(-0.2698277469542874),\n",
       " 'cat__manufacturer_datsun': np.float64(0.9948372223692685),\n",
       " 'cat__manufacturer_dodge': np.float64(-0.35935900417221167),\n",
       " 'cat__manufacturer_ferrari': np.float64(1.4697247276833296),\n",
       " 'cat__manufacturer_fiat': np.float64(-0.6540859422445756),\n",
       " 'cat__manufacturer_ford': np.float64(-0.09496931495343022),\n",
       " 'cat__manufacturer_gmc': np.float64(-0.047172122028170796),\n",
       " 'cat__manufacturer_harley-davidson': np.float64(-0.19851903948043612),\n",
       " 'cat__manufacturer_honda': np.float64(-0.10710556329785184),\n",
       " 'cat__manufacturer_hyundai': np.float64(-0.17203260119614164),\n",
       " 'cat__manufacturer_infiniti': np.float64(0.08894383549223128),\n",
       " 'cat__manufacturer_jaguar': np.float64(0.03660218418731975),\n",
       " 'cat__manufacturer_jeep': np.float64(-0.030488767694854535),\n",
       " 'cat__manufacturer_kia': np.float64(-0.1852421868420555),\n",
       " 'cat__manufacturer_land rover': np.float64(-0.24560605722865783),\n",
       " 'cat__manufacturer_lexus': np.float64(0.21725450948773647),\n",
       " 'cat__manufacturer_lincoln': np.float64(0.18159226304581347),\n",
       " 'cat__manufacturer_mazda': np.float64(-0.25027579154237434),\n",
       " 'cat__manufacturer_mercedes-benz': np.float64(-0.06014700367461209),\n",
       " 'cat__manufacturer_mercury': np.float64(-0.5872747882402589),\n",
       " 'cat__manufacturer_mini': np.float64(-0.14168740117920456),\n",
       " 'cat__manufacturer_mitsubishi': np.float64(-0.29606146506439546),\n",
       " 'cat__manufacturer_nissan': np.float64(-0.23228468989534562),\n",
       " 'cat__manufacturer_pontiac': np.float64(-0.18154353157202274),\n",
       " 'cat__manufacturer_porsche': np.float64(0.39754457001836047),\n",
       " 'cat__manufacturer_ram': np.float64(-0.038987709577450735),\n",
       " 'cat__manufacturer_rover': np.float64(0.2343108937831032),\n",
       " 'cat__manufacturer_saturn': np.float64(-0.6108996060146282),\n",
       " 'cat__manufacturer_subaru': np.float64(-0.074750191233795),\n",
       " 'cat__manufacturer_tesla': np.float64(0.6033135965968942),\n",
       " 'cat__manufacturer_toyota': np.float64(0.008156085998086537),\n",
       " 'cat__manufacturer_volkswagen': np.float64(-0.1680782670212433),\n",
       " 'cat__manufacturer_volvo': np.float64(-0.05007994762809201),\n",
       " 'cat__fuel_diesel': np.float64(0.3331726126564855),\n",
       " 'cat__fuel_electric': np.float64(-0.009674390508090672),\n",
       " 'cat__fuel_gas': np.float64(-0.173369297643982),\n",
       " 'cat__fuel_hybrid': np.float64(-0.11224097010280795),\n",
       " 'cat__fuel_other': np.float64(-0.03788795440159509),\n",
       " 'cat__type_SUV': np.float64(-0.13271370502508173),\n",
       " 'cat__type_bus': np.float64(0.021036218329537396),\n",
       " 'cat__type_convertible': np.float64(0.218187194033047),\n",
       " 'cat__type_coupe': np.float64(0.07460424615043935),\n",
       " 'cat__type_hatchback': np.float64(-0.30182769272822163),\n",
       " 'cat__type_mini-van': np.float64(-0.19719889050565503),\n",
       " 'cat__type_offroad': np.float64(0.35344742803532175),\n",
       " 'cat__type_other': np.float64(0.19619425730660356),\n",
       " 'cat__type_pickup': np.float64(0.24244687849063093),\n",
       " 'cat__type_sedan': np.float64(-0.35578062851718883),\n",
       " 'cat__type_truck': np.float64(0.15299586207705265),\n",
       " 'cat__type_van': np.float64(0.024723200253248756),\n",
       " 'cat__type_wagon': np.float64(-0.296114367899738),\n",
       " 'cat__transmission_automatic': np.float64(-0.18011253820265322),\n",
       " 'cat__transmission_manual': np.float64(-0.041762377221299274),\n",
       " 'cat__transmission_other': np.float64(0.22187491542395682),\n",
       " 'cat__drive_4wd': np.float64(0.010592926963818194),\n",
       " 'cat__drive_fwd': np.float64(-0.18746465533354234),\n",
       " 'cat__drive_rwd': np.float64(0.17687172836973486),\n",
       " 'cat__paint_color_black': np.float64(0.08158445276315973),\n",
       " 'cat__paint_color_blue': np.float64(-0.011025802915535177),\n",
       " 'cat__paint_color_brown': np.float64(-0.04166091217777354),\n",
       " 'cat__paint_color_custom': np.float64(0.004690935253744616),\n",
       " 'cat__paint_color_green': np.float64(-0.13085368193669816),\n",
       " 'cat__paint_color_grey': np.float64(-0.02459528729895552),\n",
       " 'cat__paint_color_orange': np.float64(0.1722303579929346),\n",
       " 'cat__paint_color_purple': np.float64(0.05008538225068976),\n",
       " 'cat__paint_color_red': np.float64(0.03174040938436601),\n",
       " 'cat__paint_color_silver': np.float64(-0.047975714346665366),\n",
       " 'cat__paint_color_unknown': np.float64(-0.23362016856164952),\n",
       " 'cat__paint_color_white': np.float64(0.03240994655505236),\n",
       " 'cat__paint_color_yellow': np.float64(0.11699008303733277),\n",
       " 'cat__condition_excellent': np.float64(0.3273929639319294),\n",
       " 'cat__condition_fair': np.float64(-0.6921226874230646),\n",
       " 'cat__condition_good': np.float64(0.22119736463260453),\n",
       " 'cat__condition_like new': np.float64(0.40410637268870386),\n",
       " 'cat__condition_new': np.float64(0.4059118464657473),\n",
       " 'cat__condition_salvage': np.float64(-1.0267405907230707),\n",
       " 'cat__condition_unknown': np.float64(0.36025473042715306),\n",
       " 'cat__cylinders_10 cylinders': np.float64(-0.9134843055431702),\n",
       " 'cat__cylinders_12 cylinders': np.float64(0.4382415685729746),\n",
       " 'cat__cylinders_3 cylinders': np.float64(0.07622792372515942),\n",
       " 'cat__cylinders_4 cylinders': np.float64(0.0231060555275083),\n",
       " 'cat__cylinders_5 cylinders': np.float64(-0.18182506633109868),\n",
       " 'cat__cylinders_6 cylinders': np.float64(0.09543813461971021),\n",
       " 'cat__cylinders_8 cylinders': np.float64(0.26016928771162284),\n",
       " 'cat__cylinders_other': np.float64(0.20212640171728163)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_pipe = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "linear_pipe.fit(X_train, y_train)\n",
    "\n",
    "linear_coef = linear_pipe.named_steps['model'].coef_\n",
    "linear_feats = linear_pipe.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Build dictionary with feature names as keys and coefficients as values\n",
    "coef_dict = dict(zip(linear_feats, linear_coef))\n",
    "coef_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "FEATURE IMPORTANCE ANALYSIS\n",
      "================================================================================\n",
      "\n",
      "Numeric Features (absolute coefficient):\n",
      "  year           :   0.3107\n",
      "  odometer       :   0.1053\n",
      "\n",
      "Categorical Features - Range Method (max - min):\n",
      "  manufacturer   :   2.1238\n",
      "  condition      :   1.4327\n",
      "  cylinders      :   1.3517\n",
      "  type           :   0.7092\n",
      "  fuel           :   0.5065\n",
      "  paint          :   0.4059\n",
      "  transmission   :   0.4020\n",
      "  drive          :   0.3643\n",
      "\n",
      "Categorical Features - Standard Deviation:\n",
      "  condition      :   0.5538\n",
      "  manufacturer   :   0.3886\n",
      "  cylinders      :   0.3846\n",
      "  type           :   0.2256\n",
      "  fuel           :   0.1762\n",
      "  transmission   :   0.1667\n",
      "  drive          :   0.1489\n",
      "  paint          :   0.1004\n",
      "\n",
      "Categorical Features - Mean Absolute Value:\n",
      "  condition      :   0.4911\n",
      "  cylinders      :   0.2738\n",
      "  manufacturer   :   0.2608\n",
      "  type           :   0.1975\n",
      "  transmission   :   0.1479\n",
      "  fuel           :   0.1333\n",
      "  drive          :   0.1250\n",
      "  paint          :   0.0753\n",
      "\n",
      "================================================================================\n",
      "ALL FEATURES RANKED BY IMPORTANCE (Range method for categorical)\n",
      "================================================================================\n",
      " 1. cat_manufacturer         :   2.1238\n",
      " 2. cat_condition            :   1.4327\n",
      " 3. cat_cylinders            :   1.3517\n",
      " 4. cat_type                 :   0.7092\n",
      " 5. cat_fuel                 :   0.5065\n",
      " 6. cat_paint                :   0.4059\n",
      " 7. cat_transmission         :   0.4020\n",
      " 8. cat_drive                :   0.3643\n",
      " 9. num_year                 :   0.3107\n",
      "10. num_odometer             :   0.1053\n",
      "\n",
      "================================================================================\n",
      "FEATURE IMPORTANCE DATAFRAME\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Type</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manufacturer</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>2.123811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>condition</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.432652</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cylinders</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1.351726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>type</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.709228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>fuel</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.506542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>paint</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.405851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>transmission</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.401987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>drive</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>0.364336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>year</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.310655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>odometer</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>0.105257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Feature         Type  Importance\n",
       "0  manufacturer  Categorical    2.123811\n",
       "1     condition  Categorical    1.432652\n",
       "2     cylinders  Categorical    1.351726\n",
       "3          type  Categorical    0.709228\n",
       "4          fuel  Categorical    0.506542\n",
       "5         paint  Categorical    0.405851\n",
       "6  transmission  Categorical    0.401987\n",
       "7         drive  Categorical    0.364336\n",
       "8          year      Numeric    0.310655\n",
       "9      odometer      Numeric    0.105257"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Extract and interpolate categorical coefficients from coef_dict\n",
    "# Group categorical features by their base feature name and calculate importance metrics\n",
    "\n",
    "# Extract numeric features (they start with 'num__')\n",
    "numeric_importance = {}\n",
    "for feat_name, coef_val in coef_dict.items():\n",
    "    if feat_name.startswith('num__'):\n",
    "        # Remove 'num__' prefix to get original feature name\n",
    "        feature_name = feat_name.replace('num__', '')\n",
    "        # Use absolute value since features are standardized\n",
    "        numeric_importance[feature_name] = abs(coef_val)\n",
    "\n",
    "# Extract and interpolate categorical features (they start with 'cat__')\n",
    "# Group by base feature name (e.g., 'cat__manufacturer_ford' -> 'manufacturer')\n",
    "categorical_coefs_by_feature = {}\n",
    "for feat_name, coef_val in coef_dict.items():\n",
    "    if feat_name.startswith('cat__'):\n",
    "        # Extract base feature name (e.g., 'cat__manufacturer_ford' -> 'manufacturer')\n",
    "        # Remove 'cat__' prefix and split on first underscore\n",
    "        remaining = feat_name.replace('cat__', '', 1)\n",
    "        parts = remaining.split('_', 1)\n",
    "        if len(parts) == 2:\n",
    "            base_feature = parts[0]\n",
    "            category_value = parts[1]\n",
    "            \n",
    "            if base_feature not in categorical_coefs_by_feature:\n",
    "                categorical_coefs_by_feature[base_feature] = []\n",
    "            categorical_coefs_by_feature[base_feature].append(coef_val)\n",
    "\n",
    "# Calculate importance metrics for categorical features\n",
    "# Method 1: Range (max - min) - shows the spread of impact\n",
    "categorical_importance_range = {}\n",
    "for feature, coefs in categorical_coefs_by_feature.items():\n",
    "    categorical_importance_range[feature] = max(coefs) - min(coefs)\n",
    "\n",
    "# Method 2: Standard deviation - shows variability\n",
    "categorical_importance_std = {}\n",
    "for feature, coefs in categorical_coefs_by_feature.items():\n",
    "    categorical_importance_std[feature] = np.std(coefs)\n",
    "\n",
    "# Method 3: Mean absolute value - shows average impact magnitude\n",
    "categorical_importance_mean_abs = {}\n",
    "for feature, coefs in categorical_coefs_by_feature.items():\n",
    "    categorical_importance_mean_abs[feature] = np.mean(np.abs(coefs))\n",
    "\n",
    "# Display results\n",
    "print(\"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nNumeric Features (absolute coefficient):\")\n",
    "for feature, importance in sorted(numeric_importance.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {feature:15s}: {importance:8.4f}\")\n",
    "\n",
    "print(\"\\nCategorical Features - Range Method (max - min):\")\n",
    "for feature, importance in sorted(categorical_importance_range.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {feature:15s}: {importance:8.4f}\")\n",
    "\n",
    "print(\"\\nCategorical Features - Standard Deviation:\")\n",
    "for feature, importance in sorted(categorical_importance_std.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {feature:15s}: {importance:8.4f}\")\n",
    "\n",
    "print(\"\\nCategorical Features - Mean Absolute Value:\")\n",
    "for feature, importance in sorted(categorical_importance_mean_abs.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f\"  {feature:15s}: {importance:8.4f}\")\n",
    "\n",
    "# Combine all features for unified comparison (using range method for categorical)\n",
    "all_feature_importance = {\n",
    "    **{f'num_{k}': v for k, v in numeric_importance.items()},\n",
    "    **{f'cat_{k}': v for k, v in categorical_importance_range.items()}\n",
    "}\n",
    "\n",
    "# Sort by importance\n",
    "sorted_importance = sorted(all_feature_importance.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL FEATURES RANKED BY IMPORTANCE (Range method for categorical)\")\n",
    "print(\"=\" * 80)\n",
    "for i, (feature, importance) in enumerate(sorted_importance, 1):\n",
    "    print(f\"{i:2d}. {feature:25s}: {importance:8.4f}\")\n",
    "\n",
    "# Create DataFrame for easier analysis\n",
    "importance_df = pd.DataFrame({\n",
    "    'Feature': list(numeric_importance.keys()) + list(categorical_importance_range.keys()),\n",
    "    'Type': ['Numeric'] * len(numeric_importance) + ['Categorical'] * len(categorical_importance_range),\n",
    "    'Importance': list(numeric_importance.values()) + list(categorical_importance_range.values())\n",
    "})\n",
    "importance_df = importance_df.sort_values('Importance', ascending=False).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"FEATURE IMPORTANCE DATAFRAME\")\n",
    "print(\"=\" * 80)\n",
    "display(importance_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deployment\n",
    "\n",
    "Now that we've settled on our models and findings, it is time to deliver the information to the client.  You should organize your work as a basic report that details your primary findings.  Keep in mind that your audience is a group of used car dealers interested in fine-tuning their inventory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
